   -- Step 1: Create the new schema to namespace our tables
   CREATE SCHEMA code_insights;

   GRANT USAGE ON SCHEMA code_insights TO postgres, service_role, authenticated, anon;

   -- Step 2: Table to track all files from GitHub that are candidates for parsing
   CREATE TABLE code_insights.files (
       id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
       user_id UUID REFERENCES auth.users(id) NOT NULL, -- User who initiated the tracking or last manual processing
       repository_full_name TEXT NOT NULL, -- e.g., 'owner/repo'
       file_path TEXT NOT NULL, -- e.g., 'src/utils/helpers.py'
       file_hash TEXT, -- SHA-256 hash of the file content to detect changes
       language TEXT, -- e.g., 'sql_snowflake', 'python_pyspark', 'dbt'
       last_scanned_at TIMESTAMPTZ,
       parsing_status TEXT DEFAULT 'pending' NOT NULL, -- pending, processing, completed, failed, needs_reprocessing
       error_message TEXT,
       created_at TIMESTAMPTZ DEFAULT now() NOT NULL,
       updated_at TIMESTAMPTZ DEFAULT now() NOT NULL,
       UNIQUE(repository_full_name, file_path) -- Ensures a file path within a repo is tracked only once
   );
   COMMENT ON TABLE code_insights.files IS 'Central registry for all source code files tracked by the system. Uniqueness is per repo and file path.';

   -- Step 3: Table to store and version control our prompts
   CREATE TABLE code_insights.prompt_templates (
       id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
       template_name TEXT NOT NULL UNIQUE,
       system_prompt TEXT NOT NULL,
       user_prompt TEXT NOT NULL,
       model_provider TEXT NOT NULL,
       model_name TEXT NOT NULL,
       created_by UUID NOT NULL,
       created_at TIMESTAMPTZ DEFAULT now() NOT NULL,
       updated_at TIMESTAMPTZ DEFAULT now() NOT NULL
   );
   COMMENT ON TABLE code_insights.prompt_templates IS 'Manages versioned LLM prompts, allowing for easy updates and A/B testing without code deployments.';

   -- Step 4: Seed the prompt_templates table with some initial prompts
   INSERT INTO code_insights.prompt_templates (template_name, system_prompt, user_prompt, model_provider, model_name, created_by)
   VALUES 
   (
     'default_code_summary',
     'You are an expert programmer. Your task is to analyze the provided code snippet and generate a concise, one-sentence summary of its primary purpose. Additionally, identify and list the key dependencies or libraries it uses. Finally, describe its main functionality in a short paragraph.',
     'Please analyze the following code file:\n\nFile Path: {{file_path}}\n\n```{{language}}\n{{code_snippet}}\n```\n\nProvide the following in a structured JSON format:\n1. A single-sentence summary of the code''s purpose.\n2. A list of key dependencies or libraries.\n3. A short paragraph describing the main functionality.',
     'openai',
     'gpt-4.1-mini',
     '00000000-0000-0000-0000-000000000000' -- System User UUID
   )
   ON CONFLICT (template_name) DO NOTHING;

   -- Step 5: Table to manage the agentic processing jobs, acting as a queue
   CREATE TABLE code_insights.processing_jobs (
       id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
       file_id UUID REFERENCES code_insights.files(id) ON DELETE CASCADE NOT NULL,
       prompt_template_id UUID REFERENCES code_insights.prompt_templates(id) ON DELETE CASCADE NOT NULL,
       status TEXT NOT NULL DEFAULT 'pending', -- pending, leasing, processing, completed, failed
       retry_count INT DEFAULT 0,
       leased_at TIMESTAMPTZ,
       llm_model_used TEXT, -- e.g., 'gpt-4-turbo-preview'
       prompt_tokens INT,
       completion_tokens INT,
       total_tokens INT,
       processing_duration_ms INT,
       error_details TEXT,
       created_at TIMESTAMPTZ DEFAULT now() NOT NULL,
       updated_at TIMESTAMPTZ DEFAULT now() NOT NULL
   );
   COMMENT ON TABLE code_insights.processing_jobs IS 'Queue for managing asynchronous LLM processing tasks for each file and job type.';

   -- Step 6: Table for detailed, structured code summaries
   CREATE TABLE code_insights.code_summaries (
       id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
       job_id UUID REFERENCES code_insights.processing_jobs(id) ON DELETE CASCADE NOT NULL UNIQUE, -- Ensures one summary per successful job
       file_id UUID REFERENCES code_insights.files(id) ON DELETE CASCADE NOT NULL,
       summary_json JSONB NOT NULL, -- Contains business context, logic, code blocks, etc.
       created_at TIMESTAMPTZ DEFAULT now() NOT NULL
   );
   COMMENT ON TABLE code_insights.code_summaries IS 'Stores structured JSON summaries of code logic and business purpose, generated by an LLM.';

   -- Step 7: For Lineage & Knowledge Graphs, a graph data model is best
   -- Nodes can be tables, columns, views, CTEs, scripts, etc.
   CREATE TABLE code_insights.graph_nodes (
       id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
       file_id UUID REFERENCES code_insights.files(id) ON DELETE CASCADE NOT NULL,
       job_id UUID REFERENCES code_insights.processing_jobs(id) ON DELETE CASCADE, -- Link to the job that created/updated this node
       node_type TEXT NOT NULL, -- 'table', 'column', 'view', 'cte', 'script', 'file', 'function'
       node_name TEXT NOT NULL, -- Fully qualified name if possible, e.g., 'schema.table.column' or 'function_name'
       properties JSONB, -- e.g., { "schema": "public", "datatype": "varchar", "description": "...", "start_line": 10, "end_line": 25 }
       created_at TIMESTAMPTZ DEFAULT now() NOT NULL,
       -- Consider a unique constraint based on file_id, node_type, and node_name if appropriate for your use case
       UNIQUE(file_id, node_type, node_name)
   );
   COMMENT ON TABLE code_insights.graph_nodes IS 'Stores all entities (tables, columns, functions, files etc.) as nodes in a graph, identified by LLM parsing.';

   -- Step 8: Edges represent the relationships between nodes (lineage, calls, dependencies)
   CREATE TABLE code_insights.graph_edges (
       id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
       job_id UUID REFERENCES code_insights.processing_jobs(id) ON DELETE CASCADE, -- Link to the job that created/updated this edge
       source_node_id UUID REFERENCES code_insights.graph_nodes(id) ON DELETE CASCADE NOT NULL,
       target_node_id UUID REFERENCES code_insights.graph_nodes(id) ON DELETE CASCADE NOT NULL,
       relationship_type TEXT NOT NULL, -- 'reads_from', 'writes_to', 'joins_with', 'calls_function', 'imports_file'
       properties JSONB, -- e.g., { "join_type": "inner", "on_columns": ["id"], "transformation_logic": "...", "confidence_score": 0.9 }
       created_at TIMESTAMPTZ DEFAULT now() NOT NULL
   );
   COMMENT ON TABLE code_insights.graph_edges IS 'Stores the relationships (lineage, dependencies, calls) between nodes, identified by LLM parsing.';

   -- Step 9: Grant permissions to relevant roles

   -- Ensure the 'postgres' user (or the role executing migrations) owns the schema
   -- This is usually implicit if 'postgres' runs the migration, but let's be clear.
   -- If your migrations run as a different user, adjust 'postgres' accordingly.
   ALTER SCHEMA code_insights OWNER TO postgres;

   -- Grant USAGE on the schema to service_role
   GRANT USAGE ON SCHEMA code_insights TO service_role;
   GRANT USAGE ON SCHEMA code_insights TO postgres; -- postgres should already have it as owner

   -- Grant ALL privileges on ALL TABLES in the schema to service_role
   GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA code_insights TO service_role;
   GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA code_insights TO postgres; -- postgres as owner

   -- Grant ALL privileges on ALL SEQUENCES in the schema to service_role (if any were used)
   GRANT ALL PRIVILEGES ON ALL SEQUENCES IN SCHEMA code_insights TO service_role;
   GRANT ALL PRIVILEGES ON ALL SEQUENCES IN SCHEMA code_insights TO postgres;

   -- Grant EXECUTE on ALL FUNCTIONS in the schema to service_role (if any were used)
   GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA code_insights TO service_role;
   GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA code_insights TO postgres;

   -- CRITICAL: Alter default privileges for the 'postgres' user (or migration runner)
   -- This ensures that any NEW objects created in this schema by 'postgres'
   -- will automatically grant these privileges to 'service_role'.
   ALTER DEFAULT PRIVILEGES FOR ROLE postgres IN SCHEMA code_insights
      GRANT ALL ON TABLES TO service_role;

   ALTER DEFAULT PRIVILEGES FOR ROLE postgres IN SCHEMA code_insights
      GRANT ALL ON SEQUENCES TO service_role;

   ALTER DEFAULT PRIVILEGES FOR ROLE postgres IN SCHEMA code_insights
      GRANT EXECUTE ON FUNCTIONS TO service_role;

   -- Also, ensure service_role itself has these default privileges for objects it might create (less likely in this flow)
   ALTER DEFAULT PRIVILEGES FOR ROLE service_role IN SCHEMA code_insights
      GRANT ALL ON TABLES TO service_role;

   ALTER DEFAULT PRIVILEGES FOR ROLE service_role IN SCHEMA code_insights
      GRANT ALL ON SEQUENCES TO service_role;

   ALTER DEFAULT PRIVILEGES FOR ROLE service_role IN SCHEMA code_insights
      GRANT EXECUTE ON FUNCTIONS TO service_role;

   -- Re-grant to be absolutely sure after default changes
   GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA code_insights TO service_role;

   -- Create indexes for performance on frequently queried columns
   CREATE INDEX idx_files_repo_path ON code_insights.files(repository_full_name, file_path);
   CREATE INDEX idx_files_user_id ON code_insights.files(user_id);
   CREATE INDEX idx_jobs_file_id ON code_insights.processing_jobs(file_id);
   CREATE INDEX idx_jobs_status_type ON code_insights.processing_jobs(status);
   CREATE INDEX idx_summaries_file_id ON code_insights.code_summaries(file_id);
   CREATE INDEX idx_nodes_file_id ON code_insights.graph_nodes(file_id);
   CREATE INDEX idx_nodes_type_name ON code_insights.graph_nodes(node_type, node_name);
   CREATE INDEX idx_edges_source_node_id ON code_insights.graph_edges(source_node_id);
   CREATE INDEX idx_edges_target_node_id ON code_insights.graph_edges(target_node_id);